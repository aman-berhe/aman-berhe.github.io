<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tokenization</title>
</head>
<body>
    <h1>Tokenization</h1>
    <p>Tokenization is the process of splitting text into individual words or sentences. It is a fundamental step in NLP.</p>

    <h2>Python Example: Word Tokenization</h2>
    <pre><code class="python">
from nltk.tokenize import word_tokenize

text = "Natural Language Processing is fascinating!"
tokens = word_tokenize(text)
print("Tokens:", tokens)
    </code></pre>
    <p><strong>Output:</strong> Tokens: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']</p>
</body>
</html>