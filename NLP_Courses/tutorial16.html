<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced NLP with Transformers</title>
    <link rel="stylesheet" href="css/style.css">
    <style>
        .course-list ul {
            list-style-type: none;
            padding: 0;
        }
        .course-list li {
            margin: 10px 0;
            padding: 10px;
            background-color: #e8e8e8;
            border-radius: 5px;
        }
        .course-list a {
            text-decoration: none;
            color: #333;
            display: block;
        }
        
        .course-list a:hover {
            background-color: #dcdcdc;
            border-radius: 5px;
            padding: 10px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Courses</h1>
        <nav>
            <ul class="header-list">
                <li><a href="index.html">Home</a></li>
                <li><a href="cv.html">CV</a></li>
                <li><a href="publications.html">Publications</a></li>
                <li><a href="courses.html">Courses</a></li>
            </ul>
        </nav>
    </header>
    <main>
    <div class="layout">
    <div class="container">
        <section id="about">
        <h1>Advanced NLP with Transformers</h1>
        <p>Transformers are state-of-the-art models for NLP tasks, leveraging attention mechanisms.</p>
        
        <h2>Python Example: Fine-Tuning BERT</h2>
        <pre><code class="python">

            from transformers import BertTokenizer, BertForSequenceClassification
            import torch

            # Load pre-trained BERT model and tokenizer
            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
            model = BertForSequenceClassification.from_pretrained('bert-base-uncased')

            # Tokenize input
            inputs = tokenizer("Hello, how are you?", return_tensors="pt")

            # Forward pass

            outputs = model(**inputs)
            print("Logits:", outputs.logits)
        </code></pre>
        <p><strong>Output:</strong> Logits: tensor([[ 0.1234, -0.5678]])</p>
        </section>
    </div>
    </div>
    </main>
    <footer>
        <p>&copy; 2024 NLP Tutorials. All Rights Reserved.</p>
    </footer>
</body>
</html>